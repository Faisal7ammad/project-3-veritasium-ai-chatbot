{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7-MQFCb3SKv"
   },
   "source": [
    "# Veritasium - Transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zXfjWu-3b-C"
   },
   "source": [
    "## Downloading & Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6322,
     "status": "ok",
     "timestamp": 1720763233414,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "VN7C3xwT6kxP",
    "outputId": "4a4d1a5c-9fc6-47d1-cfcb-35f340ee6ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.13)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.15)\n",
      "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.7.9)\n",
      "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.16)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.85)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.6.2)\n",
      "Requirement already satisfied: mutagen in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (1.47.0)\n",
      "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (3.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
      "Requirement already satisfied: websockets>=12.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (12.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.3.0+cu121)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0->torchaudio) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->torchaudio) (12.5.82)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0->torchaudio) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain langchain_community langchain_openai yt-dlp ffmpeg-python transformers torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4861,
     "status": "ok",
     "timestamp": 1720763238262,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "EnYj_V0LVBhW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import requests\n",
    "import openai\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import json\n",
    "from google.colab import files\n",
    "from google.colab import userdata\n",
    "from google.colab import runtime\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import yt_dlp\n",
    "import ffmpeg\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3629,
     "status": "ok",
     "timestamp": 1720763241888,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "EtbZ4OCO8K5O"
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = userdata.get('Ironhack-GPT')\n",
    "GCC_API_KEY = userdata.get('BH-GCC')\n",
    "HF_TOKEN = userdata.get('HF')\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gxQfZk436iK"
   },
   "source": [
    "## Veritasium videos pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1720763241889,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "ukSSHvO-Wad-"
   },
   "outputs": [],
   "source": [
    "# Load videos metadata\n",
    "with open('/content/0-videos_metadata.json', 'r') as file:\n",
    "    videos = json.load(file)\n",
    "\n",
    "# Load categorized videos metadata\n",
    "with open('/content/1-categorized_videos_metadata.json', 'r') as file:\n",
    "    categorized_videos = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF8H7Dwxblwe"
   },
   "source": [
    "### Getting Transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V65UYEAsouvx",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Test\n",
    "''' uncomment for trying out'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1720763241889,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "4wfUrPt2btg7"
   },
   "outputs": [],
   "source": [
    "# # Function to download video from YouTube using yt-dlp\n",
    "# def download_youtube_video(video_url, output_path=\"video.mp4\"):\n",
    "#     ydl_opts = {\n",
    "#         'format': 'bestaudio/best',\n",
    "#         'outtmpl': output_path,\n",
    "#     }\n",
    "#     with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "#         ydl.download([video_url])\n",
    "#     return output_path\n",
    "\n",
    "# # Function to extract audio from video using ffmpeg\n",
    "# def extract_audio_from_video(video_path, output_audio_path=\"audio.wav\"):\n",
    "#     input_stream = ffmpeg.input(video_path)\n",
    "#     audio_stream = ffmpeg.output(input_stream, output_audio_path, format='wav', acodec='pcm_s16le', ac=1, ar='16k')\n",
    "#     ffmpeg.run(audio_stream)\n",
    "#     return output_audio_path\n",
    "\n",
    "# # Example video\n",
    "# video_url = \"https://www.youtube.com/watch?v=SQggDnScsvI\"\n",
    "# video_path = download_youtube_video(video_url)\n",
    "# audio_path = extract_audio_from_video(video_path)\n",
    "\n",
    "# print(f\"Video downloaded to: {video_path}\")\n",
    "# print(f\"Audio extracted to: {audio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1720763241889,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "Bmv1ayQ2Ew-V"
   },
   "outputs": [],
   "source": [
    "# # Check for GPU availability\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the processor and model, and move the model to the GPU\n",
    "# processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)\n",
    "\n",
    "# # Function to load audio and resample it to 16kHz\n",
    "# def load_audio(file_path):\n",
    "#     audio, sample_rate = torchaudio.load(file_path)\n",
    "#     audio = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(audio)\n",
    "#     return audio.squeeze()\n",
    "\n",
    "# # Function to chunk audio with overlap\n",
    "# def chunk_audio_with_overlap(audio, chunk_size=16000*30, overlap=16000*5):  # 30-second chunks with 5-second overlap\n",
    "#     chunks = []\n",
    "#     start = 0\n",
    "#     while start < len(audio):\n",
    "#         end = start + chunk_size\n",
    "#         chunks.append(audio[start:end])\n",
    "#         start = end - overlap\n",
    "#     return chunks\n",
    "\n",
    "# # Function to transcribe audio\n",
    "# def transcribe_audio_chunk(audio_chunk):\n",
    "#     inputs = processor(audio_chunk, return_tensors=\"pt\", sampling_rate=16000, language='en')\n",
    "#     inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to GPU\n",
    "#     with torch.no_grad():\n",
    "#         logits = model.generate(**inputs)\n",
    "#     transcription = processor.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "#     return transcription\n",
    "\n",
    "# # Load and chunk the audio with overlap\n",
    "# audio = load_audio(audio_path)\n",
    "# audio_chunks = chunk_audio_with_overlap(audio)\n",
    "\n",
    "# # Transcribe each chunk and combine transcriptions\n",
    "# full_transcription = \"\"\n",
    "# for chunk in audio_chunks:\n",
    "#     transcription = transcribe_audio_chunk(chunk)\n",
    "#     full_transcription += transcription + \" \"\n",
    "\n",
    "# # Example metadata with full transcription  // Testing a short video\n",
    "# video_metadata = {\n",
    "#     \"videoId\": \"SQggDnScsvI\", \n",
    "#     \"title\": \"How Do Chameleons Change Color?\",\n",
    "#     \"transcription\": full_transcription.strip()\n",
    "# }\n",
    "\n",
    "# print(video_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1720763241889,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "5cr1AmR-4RhS",
    "outputId": "e8c8e599-c5c2-45c8-b441-9483ae24d996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "trash\n",
    "trash\n",
    "trash\n",
    "trash\n",
    "\n",
    "'''\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1zNsx7io0rL"
   },
   "source": [
    "#### Full transcriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1jJcdZDq_PniCCk0J2-QvOnGsL9jUuKMI"
    },
    "executionInfo": {
     "elapsed": 60962,
     "status": "ok",
     "timestamp": 1720792220927,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "Djjjr7X3sizM",
    "outputId": "fadfdea7-d510-4564-b4fe-ae9a339d9c0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the processor and model, and move the model to the GPU\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\").to(device)\n",
    "\n",
    "# Function to download the video and manually extract audio using ffmpeg\n",
    "def download_video(url, video_output=\"video.mp4\", audio_output=\"audio.wav\"):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': video_output,\n",
    "        'prefer_ffmpeg': True,\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.download([url])\n",
    "\n",
    "    # Manually extract audio using ffmpeg\n",
    "    if os.path.exists(video_output):\n",
    "        ffmpeg_command = f\"ffmpeg -i {video_output} -vn -acodec pcm_s16le -ar 16000 -ac 1 {audio_output}\"\n",
    "        try:\n",
    "            subprocess.run(ffmpeg_command, shell=True, check=True)\n",
    "            if os.path.exists(audio_output):\n",
    "                return video_output, audio_output\n",
    "            else:\n",
    "                print(f\"Failed to extract audio to {audio_output}\")\n",
    "                return video_output, None\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"ffmpeg error: {e}\")\n",
    "            return video_output, None\n",
    "    else:\n",
    "        print(f\"Failed to download video to {video_output}\")\n",
    "        return None, None\n",
    "\n",
    "# Function to load audio and resample it to 16kHz\n",
    "def load_audio(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        audio, sample_rate = torchaudio.load(file_path)\n",
    "        audio = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(audio)\n",
    "        return audio.squeeze()\n",
    "    else:\n",
    "        raise RuntimeError(f\"Audio file {file_path} not found.\")\n",
    "\n",
    "# Function to chunk audio with no overlap\n",
    "def chunk_audio_with_no_overlap(audio, chunk_size=16000*15):  # 15-second chunks with no overlap performed best!\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    chunk_index = 0\n",
    "    while start < len(audio):\n",
    "        end = start + chunk_size\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "        print(f\"Chunk {chunk_index}: Start={start}, End={end}\")\n",
    "        start = end\n",
    "        chunk_index += 1\n",
    "    return chunks\n",
    "\n",
    "# Function to transcribe audio\n",
    "def transcribe_audio_chunk(audio_chunk):\n",
    "    inputs = processor(audio_chunk, return_tensors=\"pt\", sampling_rate=16000, language='en')\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to GPU\n",
    "    with torch.no_grad():\n",
    "        logits = model.generate(**inputs)\n",
    "    transcription = processor.batch_decode(logits, skip_special_tokens=True)[0]\n",
    "    return transcription\n",
    "\n",
    "# Main function to process each video\n",
    "def process_video(video):\n",
    "    url = video['url']\n",
    "    try:\n",
    "        video_file, audio_file = download_video(url, \"video.mp4\", \"audio.wav\")\n",
    "\n",
    "        if audio_file is None:\n",
    "            raise RuntimeError(\"Audio extraction failed.\")\n",
    "\n",
    "        # Load and chunk the audio\n",
    "        audio = load_audio(audio_file)\n",
    "        audio_chunks = chunk_audio_with_no_overlap(audio)\n",
    "\n",
    "        full_transcription = \"\"\n",
    "        for i, chunk in enumerate(audio_chunks):\n",
    "            transcription = transcribe_audio_chunk(chunk)\n",
    "            print(f\"Chunk {i} transcription: {transcription}\")\n",
    "            full_transcription += transcription + \"\\n\"  # Add a newline character after each chunk's transcription\n",
    "\n",
    "        # Update video metadata with transcription\n",
    "        video['transcription'] = full_transcription.strip()\n",
    "\n",
    "        # Clean up downloaded files\n",
    "        if os.path.exists(video_file):\n",
    "            os.remove(video_file)\n",
    "        if os.path.exists(audio_file):\n",
    "            os.remove(audio_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing video {video['videoId']}: {e}\")\n",
    "\n",
    "# Iterate and process each video\n",
    "for category, videos in categorized_videos.items():\n",
    "    for video in videos:\n",
    "        process_video(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1xL6NRCAned6AJGUONlPauHA_7WCMt6sV"
    },
    "executionInfo": {
     "elapsed": 6881,
     "status": "ok",
     "timestamp": 1720792405169,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "uKoMwqTjtUDZ",
    "outputId": "b4bac196-2e5e-4940-cb92-7b7b62b06813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorized_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1720792465454,
     "user": {
      "displayName": "Faisal Hammad",
      "userId": "10947845733155795104"
     },
     "user_tz": -120
    },
    "id": "XtORpfsftUMR",
    "outputId": "7d91900b-b69c-4dae-8443-0b2b45d74ba1"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b7a817b0-46cd-441a-8988-ee20b74bae13\", \"transcribed_videos_metadata.json\", 2969751)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to save categorized videos metadata to a JSON file\n",
    "def save_categorized_videos_metadata_transcribed(categorized_videos, filename=\"2-transcribed_videos_metadata.json\"):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(categorized_videos, f, indent=4)\n",
    "\n",
    "# Save the metadata to a file\n",
    "save_categorized_videos_metadata_transcribed(categorized_videos)\n",
    "\n",
    "# Download the JSON file\n",
    "files.download('2-transcribed_videos_metadata.json')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOehOJdf/Lfm7QdjNT+RxTt",
   "collapsed_sections": [
    "V65UYEAsouvx"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1mW9mVS-ZM3Nh41HiubejUQ2YrFnzmwcp",
     "timestamp": 1720760228750
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
